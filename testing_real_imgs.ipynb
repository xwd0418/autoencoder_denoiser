{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pretty much deprecated, see testing_real_imgs.py\n",
    "'''\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.image\n",
    "from glob import glob\n",
    "import torch\n",
    "from model_factory import get_model\n",
    "import argparse\n",
    "from model_factory import UNet, UNet_Single\n",
    "from hsqc_dataset import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "\"\"\"configurations\"\"\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "json_version = \"bitmap\"\n",
    "config_path = f\"/root/autoencoder_denoiser/configs_{json_version}\"\n",
    "version = \"bitmap\"\n",
    "exp_dir = f'/root/autoencoder_denoiser/exps/results_{version}'\n",
    "\n",
    "class Test():\n",
    "    def __init__(self, model_name, \n",
    "                    config_path = config_path,\n",
    "                    exp_dir = exp_dir,\n",
    "                    model_path = None) -> None:\n",
    "        self.dilation = False\n",
    "        self.resize = True\n",
    "        self.config = None\n",
    "        name = model_name\n",
    "        self.name = name\n",
    "\n",
    "        f = open(f'{config_path}/'+ name + '.json')\n",
    "        self.config = json.load(f)\n",
    "        if model_path:\n",
    "            state_dict = torch.load(model_path)\n",
    "        else:\n",
    "            experiment_path = f\"{exp_dir}/{name}/\" \n",
    "            print('load from: ', os.path.join(experiment_path, 'latest_model.pt'))\n",
    "            state_dict = torch.load(os.path.join(experiment_path, 'latest_model.pt'))\n",
    "        model = get_model(self.config)\n",
    "        # try:\n",
    "        model.load_state_dict(state_dict['model'])\n",
    "        model = torch.nn.DataParallel(model)\n",
    "        # except:\n",
    "        #     model = torch.nn.DataParallel(model)\n",
    "        #     model.load_state_dict(state_dict['model'])\n",
    "            \n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        self.model = model\n",
    "\n",
    "        \n",
    "# my_model_test = Test(\"t1_03\")\n",
    "# paper_1d_test = Test(\"paper_1d\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from:  /root/autoencoder_denoiser/exps/results_bitmap/adv/latest_model.pt\n",
      "model: Adv_Unet\n",
      "load from:  /root/autoencoder_denoiser/exps/results_bitmap/match_hist/latest_model.pt\n",
      "model :UNet\n"
     ]
    }
   ],
   "source": [
    "# dann_test = Test('adv')\n",
    "# cdan_test = Test('cdan')\n",
    "# cdan_e_test=  Test('cdan_e')\n",
    "# paper1d_test = Test(\"paper1d\")\n",
    "# match_hist_baseline_test = Test(\"match_hist\")\n",
    "# need_display = True\n",
    "# one_d_test= Test('paper_1d', config_path='/root/autoencoder_denoiser/configs')\n",
    "# CE_loss = Test(\"CE_loss_old_dataset\")\n",
    "\n",
    "my_model_test = Test(\"match_hist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper_1d_test = Test(\"paper_1d\", model_path=\"/root/autoencoder_denoiser/previous_paper_denoise/exp_results/orig_config_with_norm_v4/best_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from:  /root/autoencoder_denoiser/exps/results_bitmap/match_hist/latest_model.pt\n",
      "model :UNet\n",
      "using Byeol's real imgs: normal noise\n"
     ]
    }
   ],
   "source": [
    "my_model_test = Test(\"match_hist\")\n",
    "\n",
    "from utils import display_pics\n",
    "\n",
    "# '''creating test dataloader of real noise'''\n",
    "config = my_model_test.config\n",
    "# batch = config[\"dataset\"]['batch_size']\n",
    "# shuffle=config[\"dataset\"]['shuffle']\n",
    "need_display = True\n",
    "test_loader = DataLoader(RealNoiseDataset_Byeol(config), batch_size=2, shuffle=False, num_workers=1)\n",
    "criterion = torch.nn.MSELoss(reduction=\"sum\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clist = [(0,\"darkblue\"), (0.5,\"white\"), (1, \"darkred\")]\n",
    "custom_HSQC_cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"_\",clist)\n",
    "diff_clist = [(0,\"green\"), (0.5,\"white\"), (1, \"red\")]\n",
    "custom_diff_cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"_\",diff_clist)\n",
    "\n",
    "\n",
    "def compute_SNR(raw, noisy_img): \n",
    "    signal_position= torch.where(raw!=0)\n",
    "    # noise_position= torch.where(raw==0)\n",
    "    # prediction_error = torch.sum( torch.abs(raw-noisy_img))\n",
    " \n",
    "    avg_signal = torch.sum( torch.abs(raw))/len(signal_position[0])\n",
    "    noise_std =  torch.std(noisy_img - raw)\n",
    "    return (avg_signal/noise_std).item()\n",
    "\n",
    "def test(*model_tests):\n",
    "    for model_test in model_tests:\n",
    "        displayed=0\n",
    "        display_num = 0\n",
    "        loss = 0\n",
    "        snr = 0\n",
    "        plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "        with torch.no_grad():\n",
    "            for iter, data in enumerate(tqdm(test_loader)):\n",
    "                noise, raw = data\n",
    "                if len(raw.shape)==3:   \n",
    "                    raw, noise = raw.unsqueeze(1), noise.unsqueeze(1)\n",
    "                raw, noise = raw.to(device).float(), noise.to(device).float()\n",
    "                prediction = model_test.model.forward(noise)\n",
    "                \n",
    "                # find loss\n",
    "                # prediction = prediction.type(torch.float32)\n",
    "                ground_truth = raw\n",
    "            \n",
    "                # add adv loss !!!\n",
    "                prediction = torch.clip(prediction,-1,1)\n",
    "\n",
    "            # print(denoised_1.shape)\n",
    "            # print(ground_truth.shape)\n",
    "                loss += criterion(prediction,ground_truth )\n",
    "                snr += compute_SNR(raw, prediction)\n",
    "            \n",
    "                if need_display and displayed<10:\n",
    "                    noise_pic , prediction_pic, raw_pic = noise[1],prediction[1], raw[1]\n",
    "                    \n",
    "                \n",
    "                    test_samples_path = f\"/root/autoencoder_denoiser/testing_real_imgs_results/{model_test.name}/\"\n",
    "                    os.makedirs(test_samples_path, exist_ok=True)\n",
    "                    save_path = (os.path.join(test_samples_path, f\"sample_image{displayed}.png\"))\n",
    "                    \n",
    "                    display_pics(noise_pic[0].cpu(), prediction_pic[0].cpu(), raw_pic[0].cpu(), save_path=save_path)\n",
    "                    \n",
    "                    displayed = displayed+1\n",
    "            \n",
    "                    \n",
    "            loss /= len(test_loader.dataset)  \n",
    "            snr /=   len(test_loader.dataset)\n",
    "            print(\"test loader size:\" , len(test_loader.dataset))\n",
    "            print(f\"loss of model: {model_test.name} is {loss}\")\n",
    "            print(f\"snr of model: {model_test.name} is {snr}\")\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:33<00:00,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loader size: 59\n",
      "loss of model: paper_1d is 756.748779296875\n",
      "snr of model: paper_1d is 0.7644067255117125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test 1d :\n",
    "state_dict = torch.load('/root/autoencoder_denoiser/previous_paper_denoise/exp_results/orig_config_with_norm_v4/best_model.pt')\n",
    "specs = ( [64, 128, 1024],\n",
    "\n",
    "        [ 512, 256, 64])\n",
    "\n",
    "\n",
    "model = UNet_Single(1,1,False,1,channel_specs= specs)\n",
    "model.load_state_dict(state_dict['model'])\n",
    "model = torch.nn.DataParallel(model).to(\"cuda\")\n",
    "\n",
    "displayed=0\n",
    "display_num = 0\n",
    "loss = 0\n",
    "snr = 0\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "\n",
    "def normalize_perdiction(prediction):\n",
    "    \"\"\"normalizing the prediction result\"\"\"\n",
    "    prediction = prediction.double()\n",
    "            # print(prediction)\n",
    "    prediction /= torch.max(torch.abs(prediction))\n",
    "    return prediction\n",
    "\n",
    "with torch.no_grad():\n",
    "    for iter, data in enumerate(tqdm(test_loader)):\n",
    "        noise, raw = data\n",
    "        raw, noise = raw.to(device).float(), noise.to(device).float()\n",
    "        \n",
    "        prediction = torch.zeros(noise.shape).to(\"cuda\")\n",
    "        for i in range(len(prediction)):\n",
    "            for j in range(len(prediction[i][0])):\n",
    "                curr = noise[i][0][j]\n",
    "                signs = torch.sign(curr)\n",
    "                prediction[i][0][j] = normalize_perdiction(model.forward((curr))) * signs\n",
    "                \n",
    "        loss += criterion(prediction,raw )\n",
    "        snr += compute_SNR(raw, prediction)\n",
    "  \n",
    "\n",
    "    \n",
    "        if need_display and displayed<2:\n",
    "                noise_pic , prediction_pic, raw_pic = noise[1],prediction[1], raw[1]\n",
    "                \n",
    "        test_samples_path = f\"/root/autoencoder_denoiser/testing_real_imgs_results/paper_1d/\"\n",
    "        os.makedirs(test_samples_path, exist_ok=True)\n",
    "        save_path = (os.path.join(test_samples_path, f\"sample_image{displayed}.png\"))\n",
    "        \n",
    "        display_pics(noise_pic[0].cpu(), prediction_pic[0].cpu(), raw_pic[0].cpu(), save_path=save_path)\n",
    "        \n",
    "        displayed = displayed+1\n",
    "    \n",
    "            \n",
    "    loss /= len(test_loader.dataset)  \n",
    "    snr /=  len(test_loader.dataset)\n",
    "    print(\"test loader size:\" , len(test_loader.dataset))\n",
    "    print(f\"loss of model: paper_1d is {loss}\")\n",
    "    print(f\"snr of model: paper_1d is {snr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 3.], dtype=torch.float64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3]).double()\n",
    "torch.where(a > 1.3,a ,0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,16)\n",
    "\n",
    "# test(match_hist_baseline_test )\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:11<00:00,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loader size: 59\n",
      "loss of model: match_hist is 141.350830078125\n",
      "snr of model: match_hist is 6.2938682184381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test( my_model_test)\n",
    "# test( paper_1d_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'super_noisy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_954/950344056.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"figure.figsize\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m test_loader = DataLoader(RealNoiseDataset_Byeol(dann_test.config,range_low=0,range_high=2, show_name=True),\n\u001b[0m\u001b[1;32m      7\u001b[0m                          batch_size=1, shuffle=False, num_workers=8)\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/autoencoder_denoiser/hsqc_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, range_low, range_high, show_name)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshow_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'super_noisy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_folder_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"resized_super_noisy_1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"using Byeol's real imgs: super noisy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'super_noisy'"
     ]
    }
   ],
   "source": [
    "'''testing thresholding'''\n",
    "from hsqc_dataset import *\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "\n",
    "test_loader = DataLoader(RealNoiseDataset_Byeol(dann_test.config,range_low=0,range_high=2, show_name=True),\n",
    "                         batch_size=1, shuffle=False, num_workers=8)\n",
    "\n",
    "\n",
    "def test_thresholding(test_loader, threshold_value = 0.4, dir_name_to_save = \"resized_thresholding\"):\n",
    "    testing_result_dir = f'/root/autoencoder_denoiser/testing_real_imgs_results/{test_loader.dataset.data_folder_name}_{dir_name_to_save}/'\n",
    "    os.makedirs(testing_result_dir, exist_ok= True)\n",
    "    displayed=0\n",
    "    display_num = 0\n",
    "    loss = 0\n",
    "    snr = 0\n",
    "    snr_orig = 0\n",
    "    with torch.no_grad():\n",
    "        for iter, data in enumerate(tqdm(test_loader)):\n",
    "            noise, raw,name = data\n",
    "            name = \"\".join([chr(i) for i in name[0]])\n",
    "            if len(raw.shape)==3:   \n",
    "                raw, noise = raw.unsqueeze(1), noise.unsqueeze(1)\n",
    "            prediction = torch.clone(noise)\n",
    "            prediction[abs(prediction)<threshold_value]=0\n",
    "        \n",
    "        # find loss\n",
    "        # prediction = prediction.type(torch.float32)\n",
    "            ground_truth = raw\n",
    "    \n",
    "        # add adv loss !!!\n",
    "            prediction = torch.clip(prediction,-1,1)\n",
    "\n",
    "    # print(denoised_1.shape)\n",
    "    # print(ground_truth.shape)\n",
    "            loss += criterion(prediction,ground_truth )\n",
    "            snr += compute_SNR(raw, prediction)\n",
    "            snr_orig += compute_SNR(raw, noise)\n",
    "    \n",
    "        # if need_display and displayed<2:\n",
    "            if False:\n",
    "                noise_pic , prediction_pic, raw_pic = noise[0],prediction[0], raw[0]\n",
    "            \n",
    "            # print(\"?\")\n",
    "            # plt.clf()\n",
    "\n",
    "                ax = plt.subplot(2, 2, 1)\n",
    "                plt.tight_layout()\n",
    "                ax.set_title('original',fontsize=18)\n",
    "            # ax.axis('off')\n",
    "                plt.imshow(raw_pic[0].cpu(),cmap=custom_HSQC_cmap, vmax=1, vmin=-1)\n",
    "                plt.colorbar()\n",
    "            \n",
    "                ax = plt.subplot(2, 2, 2)\n",
    "                plt.tight_layout()\n",
    "                ax.set_title('noise',fontsize=18)\n",
    "            # ax.axis('off')\n",
    "                plt.imshow(noise_pic[0].cpu(),cmap=custom_HSQC_cmap, vmax=1, vmin=-1)\n",
    "                plt.colorbar()\n",
    "            \n",
    "                ax = plt.subplot(2, 2, 3)\n",
    "                plt.tight_layout()\n",
    "                ax.set_title('predicted',fontsize=18)\n",
    "            # ax.axis('off')\n",
    "                plt.imshow(prediction_pic[0].cpu(),cmap=custom_HSQC_cmap, vmax=1, vmin=-1)\n",
    "                plt.colorbar()\n",
    "            \n",
    "                ax = plt.subplot(2, 2, 4)\n",
    "                plt.tight_layout()\n",
    "                ax.set_title('difference', fontsize=18)\n",
    "            # ax.axis('off')\n",
    "            \n",
    "            # difference = prediction_pic[0].cpu()-raw_pic[0].cpu()\n",
    "            # difference = difference.float()/2 + 0.5\n",
    "            # print(difference)\n",
    "                difference = cv2.subtract(np.array(prediction_pic[0].cpu()), np.array(raw_pic[0].cpu()))\n",
    "                plt.imshow(difference, cmap = custom_diff_cmap, vmax=1, vmin=-1)\n",
    "            \n",
    "                plt.colorbar()\n",
    "                plt.savefig(f'/root/autoencoder_denoiser/testing_real_imgs_results_bitmaps/{dir_name_to_save}/result_{name}.png')\n",
    "                plt.clf()\n",
    "                plt.figure()\n",
    "\n",
    "                displayed = displayed+1\n",
    "            \n",
    "        loss /= len(test_loader.dataset)  \n",
    "        snr /=   len(test_loader.dataset)\n",
    "        snr_orig /=   len(test_loader.dataset)\n",
    "\n",
    "        print(\"test loader size:\" , len(test_loader.dataset))\n",
    "        print(f\"loss of model: thresholding is {loss}\")\n",
    "        print(f\"snr of model: thresholding is {snr}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:02<00:00,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loader size: 22\n",
      "loss of model: thresholding is 5.9233598709106445\n",
      "snr of model: thresholding is 89.25157668373801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_thresholding(test_loader, threshold_value = 0.4 , dir_name_to_save = \"resized_thresholding\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(f'{config_path}/'+ 'adv' + '.json')\n",
    "config = json.load(f)\n",
    "config['dataset']['real_img_keep_size'] = True \n",
    "test_loader = DataLoader(RealNoiseDataset_Byeol(config,range_low=0,range_high=2, show_name=True),\n",
    "                         batch_size=1, shuffle=False, num_workers=8)\n",
    "\n",
    "# test_thresholding(test_loader, threshold_value = 0.4 , dir_name_to_save = \"orig_size_thresholding\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in test_loader:\n",
    "    noise, raw,name = data\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65630720\n",
      "4\n",
      "65630720\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([98132])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chr(104)\n",
    "print(noise.nelement())\n",
    "print(noise.element_size())\n",
    "# sys.getsizeof(noise)\n",
    "\n",
    "a= raw.to_sparse()\n",
    "\n",
    "print(a.nelement())\n",
    "print(a.element_size())\n",
    "\n",
    "a.values().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_test = Test('baseline', config_path='/root/autoencoder_denoiser/configs_4.13_solved_iterator_bug',\n",
    "                    #  exp_dir='/root/autoencoder_denoiser/exps/results_4.13_solved_iterator_bug')\n",
    "# test(baseline_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # my_model_test = Test(\"t1_03\")\n",
    "# baseline_test = Test('paper_1d', config_path='/root/autoencoder_denoiser/configs',\n",
    "#                      exp_dir='/root/autoencoder_denoiser/exps/results_4.13_solved_iterator_bug')\n",
    "# test(baseline_test)\n",
    "# # paper_1d_test = Test(\"paper_1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loop_iterable(iterable):\n",
    "#     while True:\n",
    "#         yield from iterable\n",
    "# a=  (loop_iterable([1,2,3,4,5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = zip([1,2],3,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json, torch\n",
    "# f = open('/root/autoencoder_denoiser/configs/'+ 't1_03' + '.json')\n",
    "# config = json.load(f)\n",
    "\n",
    "# state_dict = torch.load('/root/autoencoder_denoiser/results_new_SNR/t1_03/latest_model.pt')\n",
    "# model = get_model(config)\n",
    "# model = torch.nn.DataParallel(model)\n",
    "# model.load_state_dict(state_dict['model'])\n",
    "\n",
    "# torch.save(model.module.state_dict(), '/root/autoencoder_denoiser/results_new_SNR/t1_03/latest_model_weight.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "529\n"
     ]
    }
   ],
   "source": [
    "def tt(*nums):\n",
    "    for n in nums:\n",
    "        print(n**2)\n",
    "        \n",
    "tt(12,23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, torch\n",
    "a = torch.tensor([0,0,0,0,0,1,0,0,0,2])\n",
    "a.to_sparse()\n",
    "sys.getsizeof(a)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
